---
layout: post
title: Attention Is All You Need
description: ""
tags: [deeplearning]
category: Recommenter System
imagefeature: cover6.jpg
comments: true
share: true
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

本篇文章提出了仅仅依赖注意力机制(attention)的神经网络翻译结构Transformer。相比较RNN和CNN而言，Transformer在取得更好的效果的同时，能够并行化，减少了训练时间。

#### 模型架构
![transformer架构](/images/nlp/transformer_1.png)

**<center>transformer结构</center>**

